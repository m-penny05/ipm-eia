{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: thefuzz 0.22.1 does not provide the extra 'levenshtein'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting thefuzz[levenshtein]\n",
      "  Downloading thefuzz-0.22.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.0.0 (from thefuzz[levenshtein])\n",
      "  Downloading rapidfuzz-3.9.4-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Downloading rapidfuzz-3.9.4-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.6 MB 653.6 kB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.1/1.6 MB 1.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.9/1.6 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.4/1.6 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 5.7 MB/s eta 0:00:00\n",
      "Downloading thefuzz-0.22.1-py3-none-any.whl (8.2 kB)\n",
      "Installing collected packages: rapidfuzz, thefuzz\n",
      "Successfully installed rapidfuzz-3.9.4 thefuzz-0.22.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pip install thefuzz[levenshtein]\n",
    "\n",
    "import thefuzz\n",
    "\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # importing EIA sheet \n",
    "columns_to_use = ['Plant Name', 'State', 'Technology', 'Summer Capacity (MW)', 'County']\n",
    "df_eia = pd.read_excel(io=\"EIA2023.xlsx\",sheet_name=\"Operable\", usecols=columns_to_use, skiprows = 2)\n",
    "# change the read excel to whereever the file is located and check which row the column headers are located in bc then you might not need to skip 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_eia' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# This is summing all plant types with the same name to just be one plant and adding up all their summer capacity\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m numeric_columns \u001b[38;5;241m=\u001b[39m filtered_eia\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSummer Capacity (MW)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m numeric_columns:\n\u001b[0;32m      5\u001b[0m     numeric_columns \u001b[38;5;241m=\u001b[39m numeric_columns\u001b[38;5;241m.\u001b[39mappend(pd\u001b[38;5;241m.\u001b[39mIndex([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSummer Capacity (MW)\u001b[39m\u001b[38;5;124m'\u001b[39m]))  \u001b[38;5;66;03m# Indent this line\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filtered_eia' is not defined"
     ]
    }
   ],
   "source": [
    "# This is summing all plant types with the same name to just be one plant and adding up all their summer capacity\n",
    "numeric_columns = df_eia.select_dtypes(include=['number']).columns\n",
    "\n",
    "if 'Summer Capacity (MW)' not in numeric_columns:\n",
    "    numeric_columns = numeric_columns.append(pd.Index(['Summer Capacity (MW)']))  # Indent this line\n",
    "\n",
    "grouped_eia = df_eia.groupby('Plant Name', as_index=False)[numeric_columns].sum()\n",
    "\n",
    "plant_info = df_eia[['Plant Name', 'State', 'County', 'Technology']].drop_duplicates(subset='Plant Name')\n",
    "\n",
    "merged_eia = pd.merge(grouped_eia, plant_info, on='Plant Name', how='left')\n",
    "merged_eia = merged_eia[['Plant Name', 'State', 'County', 'Technology', 'Summer Capacity (MW)']]\n",
    "\n",
    "# Where to filter by what state we want to look at\n",
    "states_to_include = ['PA']  # Doing PA as a test case\n",
    "filtered_eia = merged_eia[merged_eia['State'].isin(states_to_include)]\n",
    "\n",
    "\n",
    "eia_TT_dict = {\n",
    "    'Solar Photovoltaic': 'Solar PV',\n",
    "    'Batteries': 'Battery Storage',\n",
    "    'Natural Gas Fired Combined Cycle': 'CC',\n",
    "    'Natural Gas Fired Combustion Turbine': 'CT',\n",
    "    'Onshore Wind Turbine': 'Onshore Wind',\n",
    "    'Petroleum Liquids': 'CT',\n",
    "    'Conventional Steam Coal': 'Coal',\n",
    "    'Other Natural Gas': 'Other',\n",
    "    'Conventional Hydroelectric': 'Hydro',\n",
    "    'Landfill Gas': 'Other',\n",
    "    'Natural Gas Steam Turbine': 'Steam Turbine',\n",
    "    'Wood/Wood Waste Biomass': 'Other',\n",
    "    'Other Waste Biomass': 'Other',\n",
    "    'All Other': 'Other',\n",
    "    'Hydroelectric Pumped Storage': 'Hydro',\n",
    "    'Offshore Wind Turbine': 'Offshore Wind',\n",
    "    'Natural Gas Internal Combustion Engine': 'Jet Engine',\n",
    "    'Nuclear': 'Nuclear',\n",
    "    'Municipal Solid Waste': 'Other',\n",
    "    'Flywheels': 'Other'\n",
    "}\n",
    "\n",
    "# Replace values in the 'Technology' column\n",
    "filtered_eia.loc[:, 'Technology'] = filtered_eia['Technology'].replace(eia_TT_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import IPM excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use1 = ['Plant Name', 'State', 'Capacity Type - Sub Type', 'Summer Dispatchable', 'County']\n",
    "    #change file path \n",
    "df_ipm = pd.read_excel(io=\"IPM2023.xlsx\",sheet_name=\"qry\", usecols=columns_to_use1, skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is summing all plant types with the same name to just be one plant and adding up all their summer capacity\n",
    "numeric_columns = df_ipm.select_dtypes(include=['number']).columns\n",
    "\n",
    "if 'Summer Dispatchable' not in numeric_columns:\n",
    "    numeric_columns = numeric_columns.append(pd.Index(['Summer Dispatchable']))  # Indent this line\n",
    "\n",
    "grouped_ipm = df_ipm.groupby('Plant Name', as_index=False)[numeric_columns].sum()\n",
    "\n",
    "plant_info = df_ipm[['Plant Name', 'State', 'County', 'Capacity Type - Sub Type']].drop_duplicates(subset='Plant Name')\n",
    "\n",
    "merged_ipm = pd.merge(grouped_ipm, plant_info, on='Plant Name', how='left')\n",
    "merged_ipm = merged_ipm[['Plant Name', 'State', 'County', 'Capacity Type - Sub Type', 'Summer Dispatchable']]\n",
    "\n",
    "# Where to filter by what state we want to look at\n",
    "states_to_include = ['PA']  # Doing PA as a test case\n",
    "filtered_ipm = merged_ipm[merged_ipm['State'].isin(states_to_include)]\n",
    "\n",
    "\n",
    "ipm_TT_dict = {\n",
    "    'Solar PV - Solar Photovoltaic': 'Solar PV',\n",
    "    'Combustion Turbine - Combustion Turbine': 'CT',\n",
    "    'Cogen - CT - CGCTG': 'CT',\n",
    "    'Cogen - Coal CFB_SNCR_FF - Mix (Bit/WC)': 'Coal',\n",
    "    'Battery - Battery': 'Battery Storage',\n",
    "    'Combined Cycle - TD - F-Tech Turndown': 'CC',\n",
    "    'Hydro - Hydro': 'Hydro',\n",
    "    'Wind - Wind': 'Wind',\n",
    "    'Oil/Gas Steam - Natural Gas': 'Steam Turbine',\n",
    "    'Biomass Solids - Wood and Wood Waste': 'Other',\n",
    "    'Combined Cycle - TD - G-Tech Turndown': 'CC',\n",
    "    'Steam - Other - Waste': 'Other',\n",
    "    'Pumped Storage - Pumped Storage': 'Hydro',\n",
    "    'Hydro - Run of River - Run of River': 'Hydro',\n",
    "    'Jet Engine - LM6000': 'Jet Engine',\n",
    "    'Coal_WetScrubbed_ACI_SCR_FF - Bituminous': 'Coal',\n",
    "    'Fuel Cell - Fuel Cell': 'Other',\n",
    "    'Cogen - Oil/Gas - CGSTG': 'Steam Turbine',\n",
    "    'Cogen - CC - TD - D-Tech Cogen Turndown': 'CC',\n",
    "    'Landfill - Landfill Gas': 'Other',\n",
    "    'Nuclear - Nuclear': 'Nuclear',\n",
    "    'Oil/Gas Steam - Heavy Oil': 'Steam Turbine',\n",
    "    'Hydro - Reservoir': 'Hydro',\n",
    "    'Biomass Gas - BioGas': 'Other',\n",
    "    'Cogen - Biomass - Waste': 'Other',\n",
    "    'Jet Engine - LMS100': 'Jet Engine',\n",
    "    'Combined Cycle - Cycling - E-Tech Cycling': 'CC',\n",
    "    'Cogen - CC - TD - F-Tech Cogen Turndown': 'CC',\n",
    "    'Combined Cycle - Cycling - D-Tech Cycling': 'CC',\n",
    "    'Oil/Gas Steam - SNCR - Heavy Oil': 'Steam Turbine',\n",
    "    'Coal_Unscrubbed_ACI_SCR - Bituminous': 'Coal',\n",
    "    'Cogen - Other - Waste': 'Other',\n",
    "    'Combined Cycle - TD - E-Tech Turndown': 'CC',\n",
    "    'Coal_WetScrubbed_SCR - Bituminous': 'Coal',\n",
    "    'Biomass Residues - BioResidues': 'Other',\n",
    "    'Combustion Turbine - Combustion Turbine Advanced': 'CT'\n",
    "}\n",
    "\n",
    "# Replace values in the 'Technology' column\n",
    "filtered_ipm.loc[:, 'Capacity Type - Sub Type'] = filtered_ipm['Capacity Type - Sub Type'].replace(ipm_TT_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to lower case\n",
    "ipm_lower = filtered_ipm.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "#convert to lower case\n",
    "eia_lower = filtered_eia.applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the Capacity Type - Sub Type column in ipm to be called \"Technology\"\n",
    "ipm_lower.rename(columns={'Capacity Type - Sub Type': 'Technology'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ipm to eia match "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_merge(df1, df2, key1, key2, county_key, state_key, technology_key, threshold=70, limit=1):\n",
    "    \"\"\"\n",
    "    Perform fuzzy matching and merge between two DataFrames based on plant names,\n",
    "    but only if the county, state, and technology type match.\n",
    "\n",
    "    df1, df2: DataFrames to merge\n",
    "    key1, key2: Column names for plant names to merge on\n",
    "    county_key: Column names for counties to match\n",
    "    state_key: Column names for states to match\n",
    "    technology_key : Column name for technology to match\n",
    "    threshold: Minimum similarity score to consider a match\n",
    "    limit: Number of matches to return (best match)\n",
    "    \"\"\"\n",
    "    matched_names = set()\n",
    "\n",
    "    def match_row(row):\n",
    "        # Filter df2 based on matching county, state, and technology type\n",
    "        filtered_df2 = df2[(df2[county_key] == row[county_key]) & \n",
    "                           (df2[state_key] == row[state_key]) & \n",
    "                           (df2[technology_key] == row[technology_key])]\n",
    "\n",
    "        # Apply fuzzy matching on the filtered DataFrame\n",
    "        if not filtered_df2.empty and pd.notnull(row[key1]):\n",
    "            s = filtered_df2[key2].tolist()\n",
    "            best_match = process.extractOne(row[key1], s, scorer=fuzz.token_set_ratio)\n",
    "            if best_match and best_match[1] >= threshold and best_match[0] not in matched_names:\n",
    "                matched_names.add(best_match[0])\n",
    "                return best_match\n",
    "        return None\n",
    "\n",
    "    matches = df1.apply(match_row, axis=1)\n",
    "\n",
    "    # Ensure 'best_match' column is created even if no matches are found\n",
    "    df1['best_match'] = [match[0] if match else None for match in matches]\n",
    "    df1['match_score'] = [match[1] if match else None for match in matches]\n",
    "\n",
    "    # Perform the merge based on the best matches found\n",
    "    merged_df = pd.merge(df1, df2, left_on='best_match', right_on=key2, how='left')\n",
    "\n",
    "    # Check if 'best_match' column exists before dropping\n",
    "    if 'best_match' in merged_df.columns:\n",
    "        merged_df = merged_df.drop(columns=['best_match'])\n",
    "\n",
    "    # Add capacity difference column if both capacity columns exist\n",
    "    if 'Summer Capacity (MW)' in merged_df.columns and 'Summer Dispatchable' in merged_df.columns:\n",
    "        merged_df['Capacity Difference (MW)'] = merged_df['Summer Capacity (MW)'] - merged_df['Summer Dispatchable']\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "# Assuming tech_merge_eia and tech_merge_ipm are your DataFrames with columns:\n",
    "# 'Plant Name', 'County', 'State', and 'Technology Type' along with other necessary columns.\n",
    "merged_ipm_eia = fuzzy_merge(ipm_lower, eia_lower, 'Plant Name', 'Plant Name', 'County', 'State', 'Technology', threshold=70)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "# print(merged_ipm_eia.head(300).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse compare, so eia to ipm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_merge(df1, df2, key1, key2, county_key, state_key, technology_key, threshold=70, limit=1):\n",
    "    \"\"\"\n",
    "    Perform fuzzy matching and merge between two DataFrames based on plant names,\n",
    "    but only if the county, state, and technology type match.\n",
    "\n",
    "    df1, df2: DataFrames to merge\n",
    "    key1, key2: Column names for plant names to merge on\n",
    "    county_key: Column names for counties to match\n",
    "    state_key: Column names for states to match\n",
    "    technology_key : Column name for technology to match\n",
    "    threshold: Minimum similarity score to consider a match\n",
    "    limit: Number of matches to return (best match)\n",
    "    \"\"\"\n",
    "    matched_names = set()\n",
    "\n",
    "    def match_row(row):\n",
    "        # Filter df2 based on matching county, state, and technology type\n",
    "        filtered_df2 = df2[(df2[county_key] == row[county_key]) & \n",
    "                           (df2[state_key] == row[state_key]) & \n",
    "                           (df2[technology_key] == row[technology_key])]\n",
    "\n",
    "        # Apply fuzzy matching on the filtered DataFrame\n",
    "        if not filtered_df2.empty and pd.notnull(row[key1]):\n",
    "            s = filtered_df2[key2].tolist()\n",
    "            best_match = process.extractOne(row[key1], s, scorer=fuzz.token_set_ratio)\n",
    "            if best_match and best_match[1] >= threshold and best_match[0] not in matched_names:\n",
    "                matched_names.add(best_match[0])\n",
    "                return best_match\n",
    "        return None\n",
    "\n",
    "    matches = df1.apply(match_row, axis=1)\n",
    "\n",
    "    # Ensure 'best_match' column is created even if no matches are found\n",
    "    df1['best_match'] = [match[0] if match else None for match in matches]\n",
    "    df1['match_score'] = [match[1] if match else None for match in matches]\n",
    "\n",
    "    # Perform the merge based on the best matches found\n",
    "    merged_df = pd.merge(df1, df2, left_on='best_match', right_on=key2, how='left')\n",
    "\n",
    "    # Check if 'best_match' column exists before dropping\n",
    "    if 'best_match' in merged_df.columns:\n",
    "        merged_df = merged_df.drop(columns=['best_match'])\n",
    "\n",
    "    # Add capacity difference column if both capacity columns exist\n",
    "    if 'Summer Capacity (MW)' in merged_df.columns and 'Summer Dispatchable' in merged_df.columns:\n",
    "        merged_df['Capacity Difference (MW)'] = merged_df['Summer Capacity (MW)'] - merged_df['Summer Dispatchable']\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "# Assuming tech_merge_eia and tech_merge_ipm are your DataFrames with columns:\n",
    "# 'Plant Name', 'County', 'State', and 'Technology Type' along with other necessary columns.\n",
    "merged_eia_ipm = fuzzy_merge(eia_lower, ipm_lower, 'Plant Name', 'Plant Name', 'County', 'State', 'Technology', threshold=70)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "# print(merged_ipm_eia.head(300).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to excel: ??? how to do dis\n",
    "# use merged_ipm_eia for IPM to EIA matching and use merged_eia_ipm for EIA to IPM matching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
